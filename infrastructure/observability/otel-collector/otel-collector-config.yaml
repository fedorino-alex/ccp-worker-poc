receivers:
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318

  # Fluentd Forward receiver for container logs
  fluentforward:
    endpoint: 0.0.0.0:8006

processors:
  batch:
    timeout: 1s
    send_batch_size: 1024
  memory_limiter:
    limit_mib: 512
    check_interval: 5

  # Transform processor to parse JSON logs from Docker containers via Fluentd
  transform/parse_json:
    log_statements:
      - context: log
        statements:
          # Parse the JSON log body
          - set(attributes["parsed_log"], ParseJSON(body)) where IsString(body) and body != nil and Len(body) > 0

          # Extract Scopes array and flatten all scope key-value pairs to root level
          - set(attributes["scopes"], attributes["parsed_log"]["Scopes"]) where attributes["parsed_log"]["Scopes"] != nil

          # Extract trace_id and span_id from Scopes[0] if present
          - set(trace_id.string, ConvertCase(attributes["scopes"][0]["TraceId"], "lower")) where attributes["scopes"] != nil and Len(attributes["scopes"]) > 0
          - set(span_id.string, ConvertCase(attributes["scopes"][0]["SpanId"], "lower")) where attributes["scopes"] != nil and Len(attributes["scopes"]) > 0

          # merge other scopes if present to attributes collection
          - merge_maps(attributes, attributes["scopes"][1], "upsert") where attributes["scopes"] != nil and Len(attributes["scopes"]) > 1 and attributes["scopes"][1] != nil
          - merge_maps(attributes, attributes["scopes"][2], "upsert") where attributes["scopes"] != nil and Len(attributes["scopes"]) > 2 and attributes["scopes"][2] != nil
          - merge_maps(attributes, attributes["scopes"][3], "upsert") where attributes["scopes"] != nil and Len(attributes["scopes"]) > 3 and attributes["scopes"][3] != nil
          - merge_maps(attributes, attributes["scopes"][4], "upsert") where attributes["scopes"] != nil and Len(attributes["scopes"]) > 4 and attributes["scopes"][4] != nil
          - merge_maps(attributes, attributes["scopes"][5], "upsert") where attributes["scopes"] != nil and Len(attributes["scopes"]) > 5 and attributes["scopes"][5] != nil

          # Extract main .NET log fields
          - set(attributes["level"], attributes["parsed_log"]["LogLevel"]) where attributes["parsed_log"]["LogLevel"] != nil
          - set(attributes["logger"], attributes["parsed_log"]["Category"]) where attributes["parsed_log"]["Category"] != nil
          - set(attributes["message"], attributes["parsed_log"]["Message"]) where attributes["parsed_log"]["Message"] != nil

          # Set the actual log record timestamp from the .NET timestamp
          - set(time, Time(attributes["parsed_log"]["Timestamp"], "2006-01-02T15:04:05.000Z")) where attributes["parsed_log"]["Timestamp"] != nil

          # Map .NET log levels to standard severity
          - set(severity_text, "TRACE") where attributes["level"] == "Trace"
          - set(severity_text, "DEBUG") where attributes["level"] == "Debug"
          - set(severity_text, "INFO") where attributes["level"] == "Information"
          - set(severity_text, "WARN") where attributes["level"] == "Warning"
          - set(severity_text, "ERROR") where attributes["level"] == "Error"
          - set(severity_text, "FATAL") where attributes["level"] == "Critical"

          - set(attributes["service_name"], attributes["fluent.tag"]) where attributes["fluent.tag"] != nil and Len(attributes["fluent.tag"]) > 0

            # Set the body to the actual message for readability
          - set(body, attributes["message"]) where attributes["message"] != nil

  # Log-specific processors for structured data
  attributes/logs:
    actions:
      # Set service name from extracted service_name (e.g., "ccp", "worker")
      # - key: service.name
      #   action: upsert
      #   from_attribute: service_name
      # - key: service.instance.id
      #   action: upsert
      #   from_attribute: fluent.tag
      
      # Add more Loki labels for better filtering (keep cardinality low)
      - key: level
        action: upsert
        from_attribute: level
      # - key: logger
      #   action: upsert  
      #   from_attribute: logger
      # - key: instance
      #   action: upsert
      #   from_attribute: fluent.tag
      - key: worker_name
        action: upsert
        from_attribute: WorkerName
        
      # Clean up temporary attributes
      - key: fluent.tag
        action: delete
      - key: scopes
        action: delete
      - key: parsed_log
        action: delete
      - key: service_name
        action: delete
      - key: container_name
        action: delete
      - key: container_id
        action: delete
      - key: source
        action: delete
      - key: log.source
        action: delete

exporters:
  # Zipkin
  zipkin:
    endpoint: "http://zipkin:9411/api/v2/spans"

  # # Grafana Tempo
  # otlp/tempo:
  #   endpoint: "http://tempo:4317"
  #   tls:
  #     insecure: true

  # Seq (using OTLP HTTP)
  otlphttp/seq:
    endpoint: "http://seq:5341/ingest/otlp"
    headers:
      "X-Seq-ApiKey": "your-seq-api-key-here"

  # # Loki (using OTLP HTTP)
  # otlphttp/logs:
  #   endpoint: "http://loki:3100/otlp"
  #   tls:
  #     insecure: true

  # # .NET Aspire Dashboard (OTLP gRPC)
  # otlp/aspire:
  #   endpoint: "http://aspire-dashboard:18889"
  #   tls:
  #     insecure: true

  # Console for debugging
  debug:

service:
  # telemetry:
  #   logs:
  #     level: debug

  pipelines:
    traces:
      receivers: [otlp]
      processors: [memory_limiter, batch]
      exporters: [zipkin, otlphttp/seq]

    logs:
      receivers: [fluentforward]
      processors: [memory_limiter, transform/parse_json, attributes/logs, batch]
      exporters: [otlphttp/seq]

    # metrics:
    #   receivers: [otlp]
    #   processors: [memory_limiter, batch]
    #   exporters: [logging]

  extensions: [health_check]

extensions:
  health_check:
    endpoint: 0.0.0.0:13133
