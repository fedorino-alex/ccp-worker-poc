# CCP Worker POC - Control Plane Pipeline System

A distributed pipeline control plane system built with .NET 8, featuring multiple workers, Redis state management, RabbitMQ messaging, and comprehensive observability.

## Architecture

- **Control Plane (CCP)**: ASP.NET Core Web API with pipeline management
- **Workers**: Background services processing pipeline steps (validation, processing, notification)
- **Message Broker**: RabbitMQ for inter-service communication
- **State Store**: Redis for pipeline state and coordination
- **Load Balancer**: nginx for high availability
- **Observability**: OpenTelemetry with multiple trace backends

## Quick Start

```bash
# Start the complete system
docker-compose up --build

# Access the application
curl http://localhost:5000
```

## ğŸ“Š Observability & Monitoring

This project includes a comprehensive observability stack with **5 different trace backends** for comparison and testing.

### ğŸŒ **Access Points**

| Service | URL | Port | Description |
|---------|-----|------|-------------|
| **Application** | http://localhost:5000 | 5000 | Main API (via nginx load balancer) |
| **RabbitMQ Management** | http://localhost:15672 | 15672 | Message broker UI (guest/guest) |
| **Redis** | localhost:6379 | 6379 | State store |

### ğŸ” **Trace Backends (All FREE & Open Source)**

| Backend | URL | Port | Best For | Features |
|---------|-----|------|----------|----------|
| **âš¡ Zipkin** | http://localhost:9411 | 9411 | Lightweight tracing | Fast UI, low resources |
| **ğŸ“ˆ Grafana** | http://localhost:3000 | 3000 | Dashboards + Tempo | admin/admin, correlate metrics |
| **ğŸ“ Seq** | http://localhost:5341 | 5341 | Structured logging | Event analysis, queries |

### ğŸ›ï¸ **Monitoring Infrastructure**

| Service | URL | Port | Purpose |
|---------|-----|------|---------|
| **OTEL Collector** | http://localhost:13133 | 13133 | Health check, telemetry hub |
| **Prometheus Metrics** | http://localhost:8889/metrics | 8889 | Application metrics |
| **Grafana Tempo API** | http://localhost:3200 | 3200 | Tempo backend API |

### ğŸ”§ **How to Use Different Backends**

#### **For Development & Testing:**
- **Start with Jaeger**: Best overall UI for trace analysis
- **Try Zipkin**: Fastest, most lightweight option
- **Test Grafana + Tempo**: Most efficient for large scale

#### **For Production:**
- **Small/Medium**: Grafana Tempo + Grafana dashboards
- **Enterprise**: SigNoz all-in-one solution
- **High Performance**: Tempo only (lowest resource usage)

#### **Selective Startup:**
```bash
# Start only specific backends
docker-compose up redis rabbitmq otel-collector jaeger grafana tempo

# Start everything for comparison
docker-compose up --build
```

### ğŸ“‹ **Observability Features**

#### **âœ… Distributed Tracing**
- **End-to-end pipeline visibility** across all workers
- **W3C Trace Context** propagation via RabbitMQ headers
- **Performance analysis** of each pipeline step
- **Error correlation** across distributed components

#### **âœ… Service Health**
- **Health checks** for Redis and RabbitMQ
- **Dependency ordering** in docker-compose
- **Service discovery** via container networking

#### **âœ… Multiple Export Targets**
- **5 trace backends** running simultaneously
- **Console output** for development debugging
- **Prometheus metrics** for alerting
- **Structured logging** via Seq

### ğŸ¯ **Pipeline Observability**

The system provides complete visibility into pipeline execution:

1. **Pipeline Creation** â†’ CCP API creates pipeline
2. **Step Dispatch** â†’ Workers receive messages with trace context
3. **Processing** â†’ Each step creates child spans
4. **State Updates** â†’ Redis operations tracked
5. **Completion** â†’ End-to-end trace available

#### **Example Trace Flow:**
```
HTTP Request â†’ CCP-1 â†’ RabbitMQ â†’ Validation Worker â†’ Processing Worker â†’ Notification Worker
     â†“             â†“         â†“            â†“                  â†“                    â†“
 Create Span â†’ Dispatch â†’ Queue â†’ Process Step â†’ Next Step â†’ Final Step â†’ Complete
```

### ğŸ“Š **Performance Monitoring**

Each trace backend offers different insights:

- **Jaeger**: Service dependency graphs, latency percentiles
- **Grafana**: Custom dashboards, metric correlation  
- **SigNoz**: APM metrics, error rates, throughput
- **SkyWalking**: Service topology, code-level profiling
- **Zipkin**: Simple timeline analysis

### ğŸš¨ **Alerting & Debugging**

- **Health check failures** visible in docker-compose logs
- **Trace errors** captured across all backends
- **Pipeline timeouts** monitored via heartbeat system
- **Resource usage** tracked via Prometheus metrics

## ğŸ› ï¸ **Development**

### Local Development
```bash
# Start infrastructure only
docker-compose up redis rabbitmq otel-collector jaeger

# Run applications locally
dotnet run --project ccp/ccp.csproj
dotnet run --project worker/worker.csproj
```

### Configuration
- **OpenTelemetry**: Collector endpoint configurable via environment
- **Trace backends**: Enable/disable in `otel-collector-config.yaml`
- **Worker types**: validation, processing, notification
- **Scaling**: Multiple instances per worker type

## ğŸ“ **Project Structure**

```
â”œâ”€â”€ ccp/                    # Control Plane API
â”œâ”€â”€ worker/                 # Worker service
â”œâ”€â”€ shared/                 # Shared models and services
â”œâ”€â”€ docker-compose.yaml     # Complete system definition
â”œâ”€â”€ otel-collector-config.yaml  # Telemetry collection
â”œâ”€â”€ tempo.yaml             # Tempo configuration
â”œâ”€â”€ grafana-datasources.yaml    # Grafana setup
â””â”€â”€ nginx.conf             # Load balancer config
```

## ğŸ¯ **Key Features**

- **Distributed Processing**: Multi-step pipeline execution
- **High Availability**: Load balanced CCP instances
- **Fault Tolerance**: Retry logic and error handling
- **Scalability**: Multiple workers per step type
- **Observability**: Complete trace visibility
- **Message Durability**: RabbitMQ persistence
- **State Consistency**: Redis coordination

---

**Happy Tracing!** ğŸš€ Choose your favorite observability backend and monitor your distributed pipelines with confidence!